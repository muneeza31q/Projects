{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944429a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "df.text = df.text.replace(re.compile(r\"From: \\S*@\\S*\\s?\"),)\n",
    "df.text = df.text.replace(re.compile('\\s+'),\" \")\n",
    "df.text = df.text.replace(re.compile(\"\\'\"),\"\")\n",
    "\n",
    "#Data Representation\n",
    "tfidf_victorizer = TfidfVectorizer(stop_words=\"english\", min_df=3)\n",
    "\n",
    "#Binary Classification\n",
    "binary_labels = np.where(df.target < 10, 0, 1)\n",
    "Counter(binary_labels)\n",
    "X,y = df.text, binary_labels\n",
    "\n",
    "#Text Preprocessing\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)\n",
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2))\n",
    "\n",
    "pretty_confusion_matrix(y_test, pred_test)\n",
    "for scorer in [fl_score, precision_score, recall_score]:\n",
    "    name = scorer._name_\n",
    "    print(f'{name}: {scorer(y_test, pred_test, average=\"micro\"):.4f}')\n",
    "\n",
    "#EDA\n",
    "DF.describe()\n",
    "DF[\"comp.graphics\"].value_counts()\n",
    "DF.groupby(['fl.score', 'recall_score']).mean()\n",
    "\n",
    "#There is a bit of overfitting, given that the performance on the training set is way higher than on the test set. This is something that could potentially be improved with hyperparameter tuning, especially increasing regularisation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
